{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ff8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967f8dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doesn', 'haven', 'theirs', 'hadn', 'now', 'wouldn', 'weren', 'at', 'for', 'over', 'that', 'y', 'but', 'ourselves', 'both', 'm', 'there', 'needn', 'our', 'been', 'when', 'those', 'out', 'am', 'd', 'were', 'here', 'all', \"hadn't\", 'other', \"aren't\", 'mustn', 'shouldn', 'have', 'll', 'before', 'so', 'of', 'your', 'himself', 'be', 'my', \"mightn't\", 'with', 'if', 'who', \"don't\", \"mustn't\", 't', 'he', \"you're\", \"hasn't\", 'do', 'hers', 'the', 'above', 'aren', 'having', 'own', 'by', 'they', 'isn', 'whom', 'him', 'why', 'only', 'are', 'because', 'it', 'than', \"shouldn't\", 'few', \"weren't\", 'their', 'after', 'not', 'a', 'in', 'which', 'yours', \"she's\", 'below', 'hasn', 'such', \"wouldn't\", 'does', 'she', 'o', 'shan', 'its', 'on', 'each', \"didn't\", 'should', 'had', \"should've\", 'and', 'very', 've', 'an', 'down', 'these', 'his', \"doesn't\", 'nor', 'no', 'just', 'where', 'yourselves', \"wasn't\", 'herself', 'ours', \"needn't\", 'from', 's', 'can', 'you', \"it's\", 'won', 'this', 'will', 'into', 'again', \"that'll\", 'mightn', 'to', 'any', 'further', 'i', 'we', 'up', 'too', \"you'd\", 'while', 'through', \"you've\", 'doing', 'ma', 'themselves', 'was', 'is', \"you'll\", 'until', 'once', \"isn't\", 'her', 'yourself', 'or', 'didn', 'off', \"couldn't\", 'being', 'don', \"haven't\", 'between', 'then', 'myself', 'couldn', 'wasn', 'has', 'as', 'about', 'against', 're', 'me', 'under', 'most', 'more', \"shan't\", 'ain', 'did', \"won't\", 'during', 'itself', 'what', 'them', 'how', 'same', 'some'}\n",
      "['This', 'example', 'showing', 'stop', 'word', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sentence = \"This is an example showing off stop word filtration.\"\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "print(stop_words)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc7f28a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'example', 'showing', 'stop', 'word', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(example_sentence)\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in words:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "print(filtered_sentence)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa241cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wait'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code 1\n",
    "# Importing Porterstemmer from nltk library\n",
    "# Checking for the word ‘giving’ \n",
    "# from nltk.stem import PorterStemmer\n",
    "# pst = PorterStemmer()\n",
    "# pst.stem(“waiting”)\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "pst=PorterStemmer()\n",
    "pst.stem(\"waiting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82fb29b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waited:wait\n",
      "waiting:wait\n",
      "waits:wait\n"
     ]
    }
   ],
   "source": [
    "#Code\n",
    "# Checking for the list of words\n",
    "stm = [\"waited\", \"waiting\", \"waits\"]\n",
    "for word in stm :\n",
    "    print(word+ \":\" +pst.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71627fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giving:giv\n",
      "given:giv\n",
      "gives:giv\n",
      "gave:gav\n"
     ]
    }
   ],
   "source": [
    "#Code 3\n",
    "\n",
    "# Importing LancasterStemmer from nltk\n",
    "# from nltk.stem import LancasterStemmer\n",
    "# lst = LancasterStemmer()\n",
    "# stm = [“giving”, “given”, “given”, “gave”]\n",
    "# for word in stm :\n",
    "#  print(word+ “:” +lst.stem(word))\n",
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "lst = LancasterStemmer()\n",
    "stm = [\"giving\",\"given\",\"gives\",\"gave\"]\n",
    "for word in stm:\n",
    "    print(word+\":\"+lst.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7d16e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks:  rock\n",
      "corpora:  corpus\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "Lemmatizer =WordNetLemmatizer()\n",
    "print(\"rocks: \",Lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora: \",Lemmatizer.lemmatize(\"corpora\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcf360c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequency Distribution:\n",
      "<FreqDist with 15 samples and 20 outcomes>\n",
      "\n",
      "Top 5 Most Common Words:\n",
      "[('The', 2), ('fox', 2), ('the', 2), ('dog', 2), ('.', 2)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample text\n",
    "text = \"The quick brown fox jumps over the lazy dog. The dog barks, and the fox runs away.\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Create a frequency distribution\n",
    "freq_dist = FreqDist(words)\n",
    "\n",
    "# Display the frequency distribution\n",
    "print(\"Word Frequency Distribution:\")\n",
    "print(freq_dist)\n",
    "\n",
    "# Get the most common words and their frequencies\n",
    "print(\"\\nTop 5 Most Common Words:\")\n",
    "print(freq_dist.most_common(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "980695dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Shardha\n",
      "[nltk_data]     Nand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Shardha Nand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:\n",
      "The quick brown fox jumps over the lazy dog.\n",
      "\n",
      "Parts of Speech:\n",
      "The: DT\n",
      "quick: JJ\n",
      "brown: NN\n",
      "fox: NN\n",
      "jumps: VBZ\n",
      "over: IN\n",
      "the: DT\n",
      "lazy: JJ\n",
      "dog: NN\n",
      ".: .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def get_parts_of_speech(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    return pos_tags\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "    parts_of_speech = get_parts_of_speech(input_sentence)\n",
    "\n",
    "    print(\"Original Sentence:\")\n",
    "    print(input_sentence)\n",
    "    print(\"\\nParts of Speech:\")\n",
    "    for word, pos_tag in parts_of_speech:\n",
    "        print(f\"{word}: {pos_tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f982042e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'a',\n",
       " 'branch',\n",
       " 'of',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'creating',\n",
       " 'algorithms',\n",
       " 'that',\n",
       " 'enable',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'data',\n",
       " '.',\n",
       " 'It',\n",
       " 'involves',\n",
       " 'the',\n",
       " 'development',\n",
       " 'of',\n",
       " 'models',\n",
       " 'that',\n",
       " 'can',\n",
       " 'identify',\n",
       " 'patterns',\n",
       " 'and',\n",
       " 'make',\n",
       " 'predictions',\n",
       " 'without',\n",
       " 'explicit',\n",
       " 'programming',\n",
       " '.',\n",
       " 'Widely',\n",
       " 'applied',\n",
       " 'in',\n",
       " 'various',\n",
       " 'fields',\n",
       " ',',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'continues',\n",
       " 'to',\n",
       " 'drive',\n",
       " 'innovation',\n",
       " 'and',\n",
       " 'automation',\n",
       " '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.kdnuggets.com/2020/05/text-mining-python-steps-examples.html\n",
    "# Importing necessary library\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "text = \" Machine learning is a branch of artificial intelligence focused on creating algorithms that enable computers to learn from data. It involves the development of models that can identify patterns and make predictions without explicit programming. Widely applied in various fields, machine learning continues to drive innovation and automation.\"\n",
    "from nltk.tokenize import word_tokenize\n",
    "token = word_tokenize(text)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53cc0751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3817ebef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'.': 3, 'learning': 2, 'of': 2, 'that': 2, 'to': 2, 'and': 2, 'Machine': 1, 'is': 1, 'a': 1, 'branch': 1, ...})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the frequency distinct in the tokens\n",
    "# Importing FreqDist library from nltk and passing token into FreqDist\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(token)\n",
    "fdist\n",
    "# fdist.plot(30,cummulative=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc98f8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 3),\n",
       " ('learning', 2),\n",
       " ('of', 2),\n",
       " ('that', 2),\n",
       " ('to', 2),\n",
       " ('and', 2),\n",
       " ('Machine', 1),\n",
       " ('is', 1),\n",
       " ('a', 1),\n",
       " ('branch', 1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code 2\n",
    "\n",
    "# To find the frequency of top 10 words\n",
    "fdist1 = fdist.most_common(10)\n",
    "fdist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe18dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code 1\n",
    "# Importing Porterstemmer from nltk library\n",
    "# Checking for the word ‘giving’ \n",
    "# from nltk.stem import PorterStemmer\n",
    "# pst = PorterStemmer()\n",
    "# pst.stem(“waiting”)\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "pst=PorterStemmer()\n",
    "pst.stem(\"waiting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code\n",
    "# Checking for the list of words\n",
    "stm = [\"waited\", \"waiting\", \"waits\"]\n",
    "for word in stm :\n",
    "   print(word+ \":\" +pst.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stm = [\"waited\",\"waiting\",\"waits\"]\n",
    "for word in stm:\n",
    "    print(word+\":\"+pst.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eafc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code 3\n",
    "\n",
    "# Importing LancasterStemmer from nltk\n",
    "# from nltk.stem import LancasterStemmer\n",
    "# lst = LancasterStemmer()\n",
    "# stm = [“giving”, “given”, “given”, “gave”]\n",
    "# for word in stm :\n",
    "#  print(word+ “:” +lst.stem(word))\n",
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "lst = LancasterStemmer()\n",
    "stm = [\"giving\",\"given\",\"gives\",\"gave\"]\n",
    "for word in stm:\n",
    "    print(word+\":\"+lst.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "Lemmatizer =WordNetLemmatizer()\n",
    "print(\"rocks: \",Lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora: \",Lemmatizer.lemmatize(\"corpora\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b951d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing stopwors from nltk library\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "a = set(stopwords.words(\"english\"))\n",
    "text = \"Product is not good\"\n",
    "text1 = word_tokenize(text.lower())\n",
    "# text1 = word_toenize(text.lower())\n",
    "print(text1)\n",
    "stopwords = [x for x in text1 if x not in a]\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a441a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = “vote to choose a particular man or a group (party) to represent them in parliament”\n",
    "text =\" We may workhard to achieve goal\"\n",
    "#Tokenize the text\n",
    "\n",
    "text = word_tokenize(text)\n",
    "for token in text:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd37687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a6358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a6f9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8461c5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
