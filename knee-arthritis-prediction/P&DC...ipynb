{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef3fd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6853 images belonging to 8 classes.\n",
      "Found 2933 images belonging to 8 classes.\n",
      "Found 9786 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from pyswarm import pso\n",
    "\n",
    "# Define file paths for data\n",
    "data_dir = '../knee'\n",
    "\n",
    "# Get the list of classes dynamically\n",
    "import os\n",
    "classes = os.listdir(data_dir)\n",
    "\n",
    "# Create ImageDataGenerator for data augmentation and normalization\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.3)\n",
    "\n",
    "# Load and split the data into training, validation, and testing sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    classes=classes,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    classes=classes,\n",
    "    batch_size=32,\n",
    "    shuffle=False,  # Do not shuffle the validation set\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    classes=classes,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "# Create InceptionV3 model with pre-trained weights\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom head to the base model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define objective function for PSO\n",
    "def objective_function(x):\n",
    "    # Set the hyperparameters based on the particle values\n",
    "    learning_rate = x[0]\n",
    "    num_epochs = math.ceil(x[1])\n",
    "\n",
    "    # Train the model with the updated hyperparameters\n",
    "    model.fit(train_generator, validation_data=val_generator, epochs=num_epochs, verbose=0)\n",
    "\n",
    "    # Obtain the accuracy on the validation set\n",
    "    _, val_acc = model.evaluate(val_generator)\n",
    "\n",
    "    # Return the negative accuracy to maximize it in PSO\n",
    "    return -val_acc\n",
    "\n",
    "# Define self-adaptive PSO parameters\n",
    "def self_adaptive_pso(objective_function, lower_bounds, upper_bounds, max_iterations=50, swarm_size=10):\n",
    "    inertia_weight = 0.5\n",
    "    c1 = 1.5\n",
    "    c2 = 1.5\n",
    "    bounds = list(zip(lower_bounds, upper_bounds))\n",
    "\n",
    "    # Initialize particles and velocities\n",
    "    particles = np.random.uniform(lower_bounds, upper_bounds, (swarm_size, len(lower_bounds)))\n",
    "    velocities = np.random.uniform(-1, 1, (swarm_size, len(lower_bounds)))\n",
    "\n",
    "    # Initialize personal best positions and fitness values\n",
    "    personal_best_positions = particles.copy()\n",
    "    personal_best_fitness = np.array([objective_function(p) for p in particles])\n",
    "\n",
    "    # Initialize global best position and fitness value\n",
    "    global_best_index = np.argmin(personal_best_fitness)\n",
    "    global_best_position = particles[global_best_index]\n",
    "    global_best_fitness = personal_best_fitness[global_best_index]\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        for i in range(swarm_size):\n",
    "            # Update particle velocity\n",
    "            velocities[i] = inertia_weight * velocities[i] \\\n",
    "                             + c1 * np.random.rand() * (personal_best_positions[i] - particles[i]) \\\n",
    "                             + c2 * np.random.rand() * (global_best_position - particles[i])\n",
    "\n",
    "            # Update particle position\n",
    "            particles[i] += velocities[i]\n",
    "\n",
    "            # Ensure particle stays within bounds\n",
    "            particles[i] = np.clip(particles[i], lower_bounds, upper_bounds)\n",
    "\n",
    "            # Evaluate fitness of the new position\n",
    "            fitness = objective_function(particles[i])\n",
    "\n",
    "            # Update personal best if needed\n",
    "            if fitness < personal_best_fitness[i]:\n",
    "                personal_best_fitness[i] = fitness\n",
    "                personal_best_positions[i] = particles[i]\n",
    "\n",
    "                # Update global best if needed\n",
    "                if fitness < global_best_fitness:\n",
    "                    global_best_fitness = fitness\n",
    "                    global_best_position = particles[i]\n",
    "\n",
    "        # Update inertia weight (self-adaptation)\n",
    "        inertia_weight = max(0.4, inertia_weight - 0.002)\n",
    "\n",
    "    return global_best_position, global_best_fitness\n",
    "\n",
    "# Set the bounds for the hyperparameters\n",
    "lower_bounds = [0.001, 2]  # Lower bounds for learning_rate and num_epochs\n",
    "upper_bounds = [0.003, 3]  # Upper bounds for learning_rate and num_epochs\n",
    "swarm_size = 2  # Adjust the number of particles\n",
    "\n",
    "# Perform self-adaptive PSO optimization\n",
    "best_solution, best_fitness = self_adaptive_pso(objective_function, lower_bounds, upper_bounds, max_iterations=2, swarm_size=swarm_size)\n",
    "\n",
    "# Print the best solution and its fitness\n",
    "print(\"Best Solution (Learning Rate, Num Epochs):\", best_solution)\n",
    "print(\"Best Fitness (Validation Accuracy):\", -best_fitness)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_num_epochs = 2  # Set the number of epochs to 5\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=best_num_epochs)\n",
    "\n",
    "# Reset the validation generator before evaluation\n",
    "val_generator.reset()\n",
    "# Evaluate the model on the validation set\n",
    "val_pred_labels = np.argmax(model.predict(val_generator), axis=1)\n",
    "val_true_labels = val_generator.classes\n",
    "\n",
    "# Calculate classification report and confusion matrix\n",
    "report = classification_report(val_true_labels, val_pred_labels, target_names=classes)\n",
    "confusion_mat = confusion_matrix(val_true_labels, val_pred_labels)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "if 'accuracy' in model.history.history:\n",
    "    plt.plot(model.history.history['accuracy'], label='Training Accuracy')\n",
    "if 'val_accuracy' in model.history.history:\n",
    "    plt.plot(model.history.history['val_accuracy'], label='Validation Accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(model.history.history['loss'], label='Training Loss')\n",
    "plt.plot(model.history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot validation confusion matrix\n",
    "plt.imshow(confusion_mat, cmap='Blues')\n",
    "plt.xticks(np.arange(len(classes)), classes, rotation=45)\n",
    "plt.yticks(np.arange(len(classes)), classes)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Validation Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Reset the training generator before evaluation\n",
    "train_generator.reset()\n",
    "# Evaluate the model on the training set\n",
    "train_pred_labels = np.argmax(model.predict(train_generator), axis=1)\n",
    "train_true_labels = train_generator.classes\n",
    "\n",
    "# Calculate confusion matrix for training set\n",
    "train_confusion_mat = confusion_matrix(train_true_labels, train_pred_labels)\n",
    "\n",
    "# Plot training confusion matrix\n",
    "plt.imshow(train_confusion_mat, cmap='Blues')\n",
    "plt.xticks(np.arange(len(classes)), classes, rotation=45)\n",
    "plt.yticks(np.arange(len(classes)), classes)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Training Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Count the number of images per class in the training set\n",
    "num_images_per_class = [sum(train_true_labels == i) for i in range(len(classes))]\n",
    "\n",
    "# Plot line graph for number of images per class\n",
    "plt.plot(classes, num_images_per_class, marker='o')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images per Class in Training Set')\n",
    "plt.show()\n",
    "\n",
    "# Calculate ROC curves and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(val_true_labels, model.predict(val_generator)[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves for each class\n",
    "for i in range(len(classes)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{classes[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Each Class')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate error rates for each class\n",
    "error_rates = [1 - tpr[i] for i in range(len(classes))]\n",
    "print(\"Error Rates for Each Class:\")\n",
    "for i, class_name in enumerate(classes):\n",
    "    print(f\"{class_name}: {error_rates[i]:.2%}\")\n",
    "\n",
    "# Calculate number of images for each process (training, validation, testing)\n",
    "num_images_per_process = [len(train_generator.classes), len(val_generator.classes), len(test_generator.classes)]\n",
    "\n",
    "# Plot bar graph\n",
    "plt.bar(['Training', 'Validation', 'Testing'], num_images_per_process)\n",
    "plt.xlabel('Data Split')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images in Each Process')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c95a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "if 'loss' in model.history.history:\n",
    "    plt.plot(model.history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in model.history.history:\n",
    "    plt.plot(model.history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(model.history.history['loss'], label='Training Loss')\n",
    "plt.plot(model.history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot validation confusion matrix\n",
    "plt.imshow(confusion_mat, cmap='Blues')\n",
    "plt.xticks(np.arange(len(classes)), classes, rotation=45)\n",
    "plt.yticks(np.arange(len(classes)), classes)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Validation Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Reset the training generator before evaluation\n",
    "train_generator.reset()\n",
    "# Evaluate the model on the training set\n",
    "train_pred_labels = np.argmax(model.predict(train_generator), axis=1)\n",
    "train_true_labels = train_generator.classes\n",
    "\n",
    "# Calculate confusion matrix for training set\n",
    "train_confusion_mat = confusion_matrix(train_true_labels, train_pred_labels)\n",
    "\n",
    "# Plot training confusion matrix\n",
    "plt.imshow(train_confusion_mat, cmap='Blues')\n",
    "plt.xticks(np.arange(len(classes)), classes, rotation=45)\n",
    "plt.yticks(np.arange(len(classes)), classes)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Training Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Count the number of images per class in the training set\n",
    "num_images_per_class = [sum(train_true_labels == i) for i in range(len(classes))]\n",
    "\n",
    "# Plot line graph for number of images per class\n",
    "plt.plot(classes, num_images_per_class, marker='o')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images per Class in Training Set')\n",
    "plt.show()\n",
    "\n",
    "# Calculate ROC curves and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(val_true_labels, model.predict(val_generator)[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves for each class\n",
    "for i in range(len(classes)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{classes[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Each Class')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate error rates for each class\n",
    "error_rates = [1 - tpr[i] for i in range(len(classes))]\n",
    "print(\"Error Rates for Each Class:\")\n",
    "for i, class_name in enumerate(classes):\n",
    "    print(f\"{class_name}: {error_rates[i]:.2%}\")\n",
    "\n",
    "# Calculate number of images for each process (training, validation, testing)\n",
    "num_images_per_process = [len(train_generator.classes), len(val_generator.classes), len(test_generator.classes)]\n",
    "\n",
    "# Plot bar graph\n",
    "plt.bar(['Training', 'Validation', 'Testing'], num_images_per_process)\n",
    "plt.xlabel('Data Split')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images in Each Process')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba36ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "if 'loss' in model.history.history:\n",
    "    plt.plot(model.history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in model.history.history:\n",
    "    plt.plot(model.history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2477df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "if 'loss' in history.history:\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_num_epochs = 2  # Set the number of epochs to 2\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=best_num_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632660d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "if 'accuracy' in history.history:\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "if 'val_accuracy' in history.history:\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "if 'loss' in history.history:\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265cd2f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot validation confusion matrix\n",
    "plt.imshow(confusion_mat, cmap='Blues')\n",
    "plt.xticks(np.arange(len(classes)), classes, rotation=45)\n",
    "plt.yticks(np.arange(len(classes)), classes)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Validation Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Reset the training generator before evaluation\n",
    "train_generator.reset()\n",
    "# Evaluate the model on the training set\n",
    "train_pred_labels = np.argmax(model.predict(train_generator), axis=1)\n",
    "train_true_labels = train_generator.classes\n",
    "\n",
    "# Calculate confusion matrix for training set\n",
    "train_confusion_mat = confusion_matrix(train_true_labels, train_pred_labels)\n",
    "\n",
    "# Plot training confusion matrix\n",
    "plt.imshow(train_confusion_mat, cmap='Blues')\n",
    "plt.xticks(np.arange(len(classes)), classes, rotation=45)\n",
    "plt.yticks(np.arange(len(classes)), classes)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Training Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Count the number of images per class in the training set\n",
    "num_images_per_class = [sum(train_true_labels == i) for i in range(len(classes))]\n",
    "\n",
    "# Plot line graph for number of images per class\n",
    "plt.plot(classes, num_images_per_class, marker='o')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images per Class in Training Set')\n",
    "plt.show()\n",
    "\n",
    "# Calculate ROC curves and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(val_true_labels, model.predict(val_generator)[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves for each class\n",
    "for i in range(len(classes)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{classes[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Each Class')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate error rates for each class\n",
    "# Calculate error rates for each class\n",
    "error_rates = [(1 - tpr[i]) * 100 for i in range(len(classes))]  # Convert to percentage\n",
    "\n",
    "print(\"Error Rates for Each Class:\")\n",
    "for i, class_name in enumerate(classes):\n",
    "    print(f\"{class_name}: {error_rates[i]:.2f}%\")\n",
    "\n",
    "# Calculate number of images for each process (training, validation, testing)\n",
    "num_images_per_process = [len(train_generator.classes), len(val_generator.classes), len(test_generator.classes)]\n",
    "\n",
    "# Plot bar graph\n",
    "plt.bar(['Training', 'Validation', 'Testing'], num_images_per_process)\n",
    "plt.xlabel('Data Split')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images in Each Process')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea0220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print error rates for each class\n",
    "print(\"Error Rates for Each Class:\")\n",
    "for i, class_name in enumerate(classes):\n",
    "    print(f\"{class_name}: {error_rates[i][0]*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d76b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of images for each process\n",
    "num_images_per_process = [len(train_generator.classes), len(val_generator.classes), len(test_generator.classes)]\n",
    "\n",
    "# Plot bar graph\n",
    "plt.bar(['Training', 'Validation', 'Testing'], num_images_per_process)\n",
    "plt.xlabel('Data Split')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images in Each Process')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a13aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
